<!DOCTYPE html>
<html>
<head>
<title>index</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 750px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
<title>WDS Research Group | 东南大学计算机学院万维网数据科学实验室</title>
<link rel = "Shortcut Icon" href=http://wds.ac.cn/favicon.ico></link> 
<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?f0175b81e00222870b0b5da046e45ebb";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>
<body>
<p>&lt; <a href="http://wds.ac.cn">WDS Home</a></p>
<h1><center>WDS Projects </center></h1>
<p><br></p>
<h2>ACESO <font color="white" style="background-color:green" size=3>Biomedicine</font> <font color="white" style="background-color:red" size=3>NLP</font>  <font color="white" style="background-color:blue" size=3>Deep Learning</font></h2>
<p>Evidence-based medicine (EBM) involves all available evidence, such as reports from randomized controlled trials (RCTs), to aid clinical medicine. In practice, available evidence can be obtained by manually searching and analyzing a large medical literature database such as PubMed. Medical literature often appears as unstructured text in scientific publications, so that clinicians need to read the publications line by line. At the same time, deluge of medical data has led clinicians to explore a lot of medical literature in order to master the latest medical research results, which is a burden for clinicians. Efficacy of EBM will be greatly improved if existing evidence can be automatically extracted from unstructured medical literature.</p>
<p>ACESO is a system that automatically generates a summary of evidence in the medical literature under the PICO framework.We adopt an active learning paradigm, which helps to minimize the cost of producing labeled data from systematic reviews, and to optimize the quality of summarization with limited labeled data. In ACESO, Deep learning is used to learn a distributed representation of each concept in UMLS (Unified Medical Language System), and we utilize the embedding of these medical concepts as a knowledge base in summarization.</p>
<p>Functions of ACESO:
1. Multi-person collaboration labeling training set.
2. Pick useful samples automatically using the active learning paradigm.
3. Generate a literature summary and visually present summarization.</p>
<ul>
<li>Links: <a href="/projects/aceso/">ACESO</a></li>
<li>Current developers: Ping Geng, Teng Zhang, Peng Gao, Qian Lu</li>
</ul>
<h2>EnProfiler <font color="black" style="background-color:yellow" size=3>Knowledge Graph</font> <font color="white" style="background-color:blue" size=3>Deep Learning</font></h2>
<p>Knowledge Graphs (KGs) are graph-structured knowledge bases storing factual information about real-world entities. Comprehending the uniqueness of each entity is crucial to the analyzing, sharing and reusing of KGs Traditional profiling technologies encompass a vast array of methods to find distinctive
features in various applications, such as characterizing commercial users, comparing gene expression or summarizing datasets. It can also help to differentiate entities in the process of humanunderstanding of KGs. In this work, we present a novel profiling approach to identify distinctive entity features in KG.
Distinctiveness of features are carefully selected and measured by a HAS model, which is a scalable representation learning model to produce a multi-pattern entity embedding from graph structures.By using the model, we can generate the results of entity profiling.</p>
<p>This platform &quot;EnProfiler&quot; shows entity profiling  of different datasets，like dbpedia,drugbank and so on.</p>
<p>&quot;EnProfiler&quot;  is focused on the following areas:
1. Entity Profiling: Search entities and generate the profiling;
2. Label Sets: generate label sets of different types in datasets;
3. Evaluation: Provide labels for judges and evaluate quality of labels .</p>
<ul>
<li>Links: <a href="/projects/enprofiler/">EnProfiler</a></li>
<li>Current Members: Qingqing Yang, Jinru Ding, Yudong Yang</li>
</ul>
<h2>N-ary Relation Miner <font color="black" style="background-color:yellow" size=3>Knowledge Graph</font> <font color="white" style="background-color:red" size=3>NLP</font></h2>
<p>Knowledge graphs are typically represented as a set of binary relations between two entities or one
entity and a value. However, many facts about the world involve more than two entities. A
convenient way to represent certain facts is to use special relations to link multiple entities. These
relations are called n-ary relations. The awareness and understanding of these n-ary relations will be
helpful to the analysis, utilization of human knowledge in a higher order. To address this issue, many
researches have been carried on finding n-ary language patterns in unstructured text. However, we
observed that n-ary relations can also be identified in graph-structured data, such as knowledge
graphs. In this project, we analysis the structure of n-ary relations, and we present a framework to
discover these relations based on a multi-label frequent tree mining algorithm on knowledge graphs.
At last,we evaluate the framework on real-world knowledge graphs, and discuss n-ary relations vs.
correlated binary relations. </p>
<ul>
<li>Links: <a href="/projects/nary/">N-ary Relation Miner</a></li>
<li>Current Members: Binchu Liu, ChenHui Lv, Miao Yang</li>
</ul>
<h2>Lawterm <font color="white" style="background-color:red" size=3>NLP</font> <font color="white" style="background-color:blue" size=3>Deep Learning</font></h2>
<p>This study intends to propose a method to identify hypernym-hyponym relations in the field of traffic in law using tag embeddings. First, we use the neural network model to learn tag embedding, which is not only dependent on the hypernym and hyponym tags, but also dependent on the context information and its occurrence frequency. We then apply such embeddings as features to identify hypernym-hyponym relations using SVM.</p>
<ul>
<li>Links: <a href="/projects/lawterm/">Lawterm</a></li>
<li>Current Members: Ziyue Wang, Peng Gao</li>
</ul>

</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
